{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ps06_pagerank.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzV0kVQmFQC6"
      },
      "source": [
        "# Practice Session 06: PageRank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRDS-2-uFQDE"
      },
      "source": [
        "# 1. Read host names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce-k81hFFQDH"
      },
      "source": [
        "import io\n",
        "import gzip\n",
        "import csv\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L50MQBcFQDK"
      },
      "source": [
        "INPUT_NODES_FILENAME = \"webspam_uk2007-nodes.csv.gz\"\n",
        "INPUT_EDGES_FILENAME = \"webspam_uk2007-edges.csv.gz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP8FWX4jFQDM"
      },
      "source": [
        "name2id = {} #Creamos los 3 diccionarios\n",
        "id2name = {} \n",
        "id2label = {}\n",
        "with gzip.open(INPUT_NODES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
        "    reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
        "    for record in reader:\n",
        "        name2id[record[\"hostname\"]] = int(record[\"nodeid\"])#Key hostname. devuelve la id del nodo que se corresponde a ese nombre\n",
        "        id2name[int(record[\"nodeid\"])] = record[\"hostname\"]#Key id. devuelve el nombre que corresponde a esa id \n",
        "        id2label[int(record[\"nodeid\"])] = record[\"label\"]#Key id. devuelve el label que corresponde a esa id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwaEfkWaFQDP",
        "outputId": "1bf09372-592c-466d-ecea-a72a20dbf718"
      },
      "source": [
        "# Leave as-is\n",
        "\n",
        "print(\"%s: %s\" % (id2name[873], id2label[873]))\n",
        "print(\"%s: %s\" % (id2name[105715], id2label[105715]))\n",
        "print(\"Number of hosts: %s\" % len(id2name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bbc.co.uk: nonspam\n",
            "www.top-mobile-phones.co.uk: spam\n",
            "Number of hosts: 114529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl8e1JvjFQDT",
        "outputId": "830fed38-ce91-4c15-9036-eb3c54364087"
      },
      "source": [
        "spam = 0\n",
        "nonspam = 0\n",
        "unlabeled = 0\n",
        "#miramos las labels de todos los nodos y contamos las veces que aparece spam, las veces que aparece nonspam y las veces que aparace unlabeled.\n",
        "for i in range(len(id2label)):\n",
        "    if id2label[i] == 'spam':\n",
        "        spam+=1\n",
        "    elif id2label[i] == 'nonspam':\n",
        "        nonspam+=1\n",
        "    elif id2label[i] == 'unlabeled':\n",
        "        unlabeled+=1\n",
        "print(\"%d, %d, %d\" % (spam, nonspam, unlabeled))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "344, 5709, 108476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgDNQHp5FQDV",
        "outputId": "8393172c-3496-4ee9-b83d-eae68f1afaa1"
      },
      "source": [
        "with gzip.open(INPUT_EDGES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
        "    reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
        "    spammywords = ['escort', 'xx', 'girl', 'credit', 'mortgage', 'finance', 'debt', 'loan']#Lista de palabras que si aparecen se consideraran spam\n",
        "    g = nx.DiGraph()#creamos un grafo dirigido\n",
        "    for record in reader:\n",
        "        for word in spammywords:#revisamos si alguna de las palabras de la lista esta en el nodo source o en el de destino, ademas miramos que la label del source y del destino no sea unlabeled.\n",
        "            if((word in id2name[int(record[\"source\"])] or word in id2name[int(record[\"destination\"])])and id2label[int(record[\"source\"])] != \"unlabeled\" and id2label[int(record[\"destination\"])]!= \"unlabeled\"):\n",
        "                g.add_edge(id2name[int(record[\"source\"])], id2name[int(record[\"destination\"])])#Añadimos el enlace al grafo\n",
        "print(g.number_of_nodes())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbZUO0UaFQDY"
      },
      "source": [
        "# Leave this code as-is, or modify slightly\n",
        "\n",
        "colors = []\n",
        "hostname_converted = {}\n",
        "\n",
        "for hostname in g.nodes():\n",
        "    # Assign colors to nodes according to spam/nonspam labels\n",
        "    if id2label[name2id[hostname]] == 'spam':\n",
        "        colors.append('red')\n",
        "    elif id2label[name2id[hostname]] == 'nonspam':\n",
        "        colors.append('lightgreen')\n",
        "    else:\n",
        "        colors.append('white')\n",
        "    \n",
        "    # Shorten the hostnames to generate labels    \n",
        "    label = hostname.replace(\"www.\", \"\").replace(\".uk\", \"\")\n",
        "    hostname_converted[hostname] = label\n",
        "    \n",
        "# Notice that if you re-run this cell the layout will be different every time\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.axis('off')\n",
        "pos = nx.spring_layout(g)\n",
        "nx.draw_networkx(g, pos, with_labels=True, node_size=400, node_color=colors, labels=hostname_converted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLVvpD8fF0Kd"
      },
      "source": [
        "La gran mayoria de enlaces de spam de caracter economico provienen de la pagina stopbyfinance.co, por lo que está pagina es el nodo de mayor grado y de igual manera la que mas \"spam\" proporciona a la red de la lista.\n",
        "Luego vemos que hay mas de una componente conexa, hay 2 grupos de paginas de caracter pornografico, por lo que contienen en sus nombres. En una de estas componentes hay un nodo que predomina también y la mayoria de enlaces salen o van del nodo con nombre de pagina escortnet.co.\n",
        "Hay muchas paginas o nodos con grado 1 por lo cual solo estan relacionadas con una sola pagina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrUiPZbpFQDa"
      },
      "source": [
        "# 2. Compute the degree of each node"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgEpi30PFQDa"
      },
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "id2degree = {}\n",
        "N = len(id2name)\n",
        "for nodeid in range(N):\n",
        "    id2degree[nodeid] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkmNrRwkF6jK"
      },
      "source": [
        "with gzip.open(INPUT_EDGES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
        "    reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
        "    for record in reader:\n",
        "      id2degree[int(record['source'])] += 1 #Suma 1 cada vez que se encuentra esta posicion, si el source es 0 pues suma 1 y a la siguiente igual\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwYWxsW9FQDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f11633d-dea7-4e5d-b690-fcd523f69bb2"
      },
      "source": [
        "# Leave this cell as-is\n",
        "\n",
        "for nodeid in [890, 1469, 105715]:\n",
        "    print(\"%s: degree %d\" % (id2name[nodeid], id2degree[nodeid]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bc1.org.uk: degree 16\n",
            "candycaine.skinthesun.co.uk: degree 22\n",
            "www.top-mobile-phones.co.uk: degree 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQQmBdvmFQDc"
      },
      "source": [
        "# 3. Compute PageRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_EbDWZhFQDd"
      },
      "source": [
        "# Leave this cell as-is\n",
        "\n",
        "ITERATIONS = 20\n",
        "ALPHA = 0.85\n",
        "\n",
        "pagerank_aux = [0.0] * N\n",
        "pagerank = [1.0/N] * N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s8vnCRJRLIt"
      },
      "source": [
        "\n",
        "for iteration in range(ITERATIONS):\n",
        "    i = 0\n",
        "    with gzip.open(INPUT_EDGES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
        "      reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
        "      for record in reader:\n",
        "        pagerank_aux[int(record['destination'])] += pagerank[int(record['source'])]/id2degree[int(record['source'])]#Aplicamos la formula del pagerank\n",
        "      while i < N:\n",
        "        pagerank[i] = ALPHA*pagerank_aux[i]+(1-ALPHA)*(1.0/N)\n",
        "        i+=1\n",
        "    pagerank_aux = [0.0] * N #Volvemos a poner el diccionario auxiliar a 0 para calcular correctamente el siguiente pagerank\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "256tjs3qFQDe"
      },
      "source": [
        "# 4. Nodes with largest values of PageRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "011zt9lfYHuz"
      },
      "source": [
        "i = 0\n",
        "rounded = [0.0] * N \n",
        "while i < N:\n",
        "  rounded[i] = round(pagerank[i], 6)#Redondeamos cada valor del pagerank a 6 decimales\n",
        "  i = i+1\n",
        "hosts_by_score = sorted(enumerate(rounded), key=lambda x: x[1], reverse=True) #Ordenamos el pagerank de manera descendente\n",
        "i = 0 \n",
        "while i < 20:\n",
        "  print(\"host id: %d, host name: %s, label: %s, score: %g\" % (hosts_by_score[i][0], id2name[hosts_by_score[i][0]], id2label[hosts_by_score[i][0]], hosts_by_score[i][1]))#Imprimimos los 20 nodos con mas pagerank.\n",
        "  i = i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhjAcBWypdwy"
      },
      "source": [
        "\n",
        "\n",
        "1.   Porque es una pagina gubernamental del reino unido donde se informa de la legislación del país, por lo que muchas paginas te llevaran a esta para darte cualquier tipo de información, mismamente en todas las paginas puede haber algo que esté relacionado con la ley de privacidad la cual si te quieres informar te redigirá a esta web.\n",
        "2.   La gran mayoria de webs son paginas de caracter gubernamental, luego se encontrarian las educacionales y finalmente las comerciales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXVvi7tvFQDg"
      },
      "source": [
        "# 5. Run non-spam PageRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LF9xKlT3_z9"
      },
      "source": [
        "id2nsdegree = {}\n",
        "N = len(id2name)\n",
        "for nodeid in range(N):\n",
        "    id2nsdegree[nodeid] = 0\n",
        "with gzip.open(INPUT_EDGES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
        "    reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
        "    for record in reader:\n",
        "        if id2label[int(record['source'])] != \"spam\" and id2label[int(record['destination'])] != \"spam\":\n",
        "            id2nsdegree[int(record['source'])] += 1#Miramos el grado de los nodos que no sean spam contando las veces que aparecen estos nodos.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TII64nGzFQDi"
      },
      "source": [
        "# Leave this cell as-is\n",
        "\n",
        "for nodeid in [890, 1469, 105715]:\n",
        "    print(\"%s: normal degree %d nospam degree %d\" % (id2name[nodeid], id2degree[nodeid], id2nsdegree[nodeid]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fujOB-uNw6Ti"
      },
      "source": [
        "pagerankns_aux = [0.0] * N\n",
        "pagerankns = [1.0/N] * N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bJS4PgCwa15"
      },
      "source": [
        "#Mismo proceso que en el pagerank pero esta vez lo realizamos solo con las palabras que no sean spam\n",
        "for iteration in range(ITERATIONS):\n",
        "    i = 0\n",
        "    with gzip.open(INPUT_EDGES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
        "      reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
        "      for record in reader:\n",
        "        if id2label[int(record['source'])] != \"spam\" and id2label[int(record['destination'])] != \"spam\":\n",
        "          pagerankns_aux[int(record['destination'])] += pagerankns[int(record['source'])]/id2nsdegree[int(record['source'])]\n",
        "      while i < N:\n",
        "        pagerankns[i] = ALPHA*pagerankns_aux[i]+(1-ALPHA)*(1.0/N)\n",
        "        i+=1\n",
        "    pagerankns_aux = [0.0] * N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7R7ROhAwbmG"
      },
      "source": [
        "#Mismo proceso que en el pagerank pero esta vez sin spam\n",
        "i = 0\n",
        "rounded = [0.0] * N \n",
        "while i < N:\n",
        "  rounded[i] = round(pagerankns[i], 6)\n",
        "  i = i+1\n",
        "hosts_by_scorens = sorted(enumerate(rounded), key=lambda x: x[1], reverse=True)\n",
        "i = 0 \n",
        "while i < 20:\n",
        "  print(\"host id: %d, host name: %s, label: %s, score: %g\" % (hosts_by_scorens[i][0], id2name[hosts_by_scorens[i][0]], id2label[hosts_by_scorens[i][0]], hosts_by_scorens[i][1]))\n",
        "  i = i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGoJGN-pFQDk"
      },
      "source": [
        "# 6. Compute spam gain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL7VBHRz-55l"
      },
      "source": [
        "spam_gain = [0.0]*N\n",
        "spam_gain_rounded = [0.0]*N\n",
        "for i in range(N):\n",
        "  spam_gain[i] = pagerank[i]/pagerankns[i]#Miramos la ganancia por el hecho de ser spam de cada nodo\n",
        "  spam_gain_rounded[i] = round(spam_gain[i], 2) #redondeamos a 2 decimales\n",
        "spam_gain_ordered = sorted(enumerate(spam_gain_rounded), key=lambda x: x[1], reverse=True) #Ordenamos la ganancia de manera descendente\n",
        "\n",
        "for j in range(50):\n",
        "  #Imprimimos los 50 con más ganancia\n",
        "    print(\"Host name: %s, spam gain: %g, host label: %s, \" % (id2name[spam_gain_ordered[j][0]], spam_gain_ordered[j][1], id2label[spam_gain_ordered[j][0]])+ \"pagerank: \"\"{:.2e}, \".format(pagerank[spam_gain_ordered[j][0]])+ \"pagerank no-spam: \"\"{:.2e}\".format(pagerankns[spam_gain_ordered[j][0]]) )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUlMftkL-6yS"
      },
      "source": [
        "Porque hay muchas webs que no tienen relación con el spam, es decir no redirigen a paginas que són consideradas spam según nuestro algoritmo por lo que el pagerank teniendo en cuenta el spam y sin tenerlo en cuenta es el mismo valor por lo que la ganancia seria 0. Por otra parte vemos que la mayoria de webs que ganan mas contando el spam se debe a que són webs que propiamente són spam y redirigen a otras paginas de spam o otras paginas redirigen a estas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlrj3PXOFQDn"
      },
      "source": [
        "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"
      ]
    }
  ]
}